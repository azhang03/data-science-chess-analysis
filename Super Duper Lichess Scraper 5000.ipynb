{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b77699c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be49a0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_TOKEN = \"I removed this for obvious reasons\"\n",
    "\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {API_TOKEN}'\n",
    "}\n",
    "\n",
    "response = requests.get('https://lichess.org/api/account', headers=headers)\n",
    "\n",
    "# if response.status_code == 200:\n",
    "#     print(response.json())\n",
    "# else:\n",
    "#     print(f\"Error fetching account data: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804213a1",
   "metadata": {},
   "source": [
    "## Getting team members from a specific team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fce16c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_members(team_id, full=False, max_members=None):\n",
    "    url = f'https://lichess.org/api/team/{team_id}/users'\n",
    "    params = {'full': str(full).lower()}\n",
    "    response = requests.get(url, stream=True)  # Use stream=True to process data incrementally\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        members = []\n",
    "        for i, line in enumerate(response.iter_lines(decode_unicode=True)):\n",
    "            if max_members and i >= max_members:\n",
    "                break  # Stop processing if reach limit that I set\n",
    "            members.append(json.loads(line))\n",
    "        return members\n",
    "    else:\n",
    "        print(f\"Error fetching team members: {response.status_code}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454aebd9",
   "metadata": {},
   "source": [
    "## Getting the games of a specific user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c05dd073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_analyzed_games(username, max_games=10, retries=3):\n",
    "    url = f'https://lichess.org/api/games/user/{username}'\n",
    "    params = {\n",
    "        'max': max_games,          # Limit the number of games\n",
    "        'analysed': 'true',        # Only fetch analyzed games\n",
    "        'evals': 'true',           # Include centipawn evaluations\n",
    "        'literate': 'true',        # Include annotations like \"mistake\" and \"inaccuracy\"\n",
    "        'sort': 'dateDesc',        # Most recent games first\n",
    "    }\n",
    "    \n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, params=params, timeout=10)\n",
    "            if response.status_code == 200:\n",
    "                return response.text  # get the PGN response as a plain string\n",
    "            elif response.status_code == 429:\n",
    "                print(f\"Rate limit hit. Retrying in {2 ** i} seconds...\")\n",
    "                time.sleep(2 ** i)  # Backoff exponentially to give it time to rest\n",
    "            else:\n",
    "                print(f\"Error fetching games for {username}: {response.status_code}\")\n",
    "                return \"\"\n",
    "        except requests.exceptions.Timeout:\n",
    "            print(f\"Timeout occurred. Retrying in {2 ** i} seconds...\")\n",
    "            time.sleep(2 ** i)\n",
    "        except requests.exceptions.ConnectionError as e:\n",
    "            print(f\"Connection error for user {username}: {e}. Retrying in {60*i} seconds...\")\n",
    "            time.sleep(60 * i) \n",
    "    return \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3570cf10",
   "metadata": {},
   "source": [
    "## Extracting the player error counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7ff17ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_mistakes(moves):\n",
    "    white_inaccuracies = white_mistakes = white_blunders = 0\n",
    "    black_inaccuracies = black_mistakes = black_blunders = 0\n",
    "\n",
    "    # Regex pattern to capture moves annotations\n",
    "    move_pattern = r'(\\d+\\.)\\s+(\\S+)(?:\\s+\\{[^}]*?(Inaccuracy|Mistake|Blunder)[^}]*?\\})?|\\d+\\.\\.\\.\\s+(\\S+)(?:\\s+\\{[^}]*?(Inaccuracy|Mistake|Blunder)[^}]*?\\})?'\n",
    "\n",
    "    matches = re.findall(move_pattern, moves)\n",
    "\n",
    "    for match in matches:\n",
    "        move_number, white_move, white_error, black_move, black_error = match\n",
    "\n",
    "        if white_move and white_error:\n",
    "            if white_error == \"Inaccuracy\":\n",
    "                white_inaccuracies += 1\n",
    "            elif white_error == \"Mistake\":\n",
    "                white_mistakes += 1\n",
    "            elif white_error == \"Blunder\":\n",
    "                white_blunders += 1\n",
    "\n",
    "        if black_move and black_error:\n",
    "            if black_error == \"Inaccuracy\":\n",
    "                black_inaccuracies += 1\n",
    "            elif black_error == \"Mistake\":\n",
    "                black_mistakes += 1\n",
    "            elif black_error == \"Blunder\":\n",
    "                black_blunders += 1\n",
    "\n",
    "    return white_inaccuracies, white_mistakes, white_blunders, black_inaccuracies, black_mistakes, black_blunders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e6c097",
   "metadata": {},
   "source": [
    "## Seperate all game data into their respective columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "797b1431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pgn_data_with_mistakes(pgn_data):\n",
    "    games = []\n",
    "    games_data = pgn_data.strip().split(\"\\n\\n\")  # Separate games based on blank lines\n",
    "\n",
    "    temp_game = None\n",
    "\n",
    "    for game in games_data:\n",
    "        if re.search(r'\\[Event \"', game):  # Can find main rows with the '[Event' tag\n",
    "            if temp_game:\n",
    "                games.append(temp_game)  # Make sure we save the last game before starting a new one\n",
    "            temp_game = {}  \n",
    "            temp_game['event'] = re.search(r'\\[Event \"(.*?)\"\\]', game).group(1)\n",
    "            temp_game['site'] = re.search(r'\\[Site \"(.*?)\"\\]', game).group(1)\n",
    "            temp_game['date'] = re.search(r'\\[Date \"(.*?)\"\\]', game).group(1)\n",
    "            temp_game['white'] = re.search(r'\\[White \"(.*?)\"\\]', game).group(1)\n",
    "            temp_game['black'] = re.search(r'\\[Black \"(.*?)\"\\]', game).group(1)\n",
    "            temp_game['result'] = re.search(r'\\[Result \"(.*?)\"\\]', game).group(1)\n",
    "            temp_game['white_elo'] = re.search(r'\\[WhiteElo \"(.*?)\"\\]', game).group(1) or \"Unknown\"\n",
    "            temp_game['black_elo'] = re.search(r'\\[BlackElo \"(.*?)\"\\]', game).group(1) or \"Unknown\"\n",
    "            temp_game['time_control'] = re.search(r'\\[TimeControl \"(.*?)\"\\]', game).group(1)\n",
    "            temp_game['eco'] = re.search(r'\\[ECO \"(.*?)\"\\]', game).group(1) or \"Unknown\"\n",
    "            temp_game['termination'] = re.search(r'\\[Termination \"(.*?)\"\\]', game).group(1) or \"Unknown\"\n",
    "        elif temp_game:\n",
    "            # For unknown rows with moves\n",
    "            moves = game.strip()\n",
    "            if not moves.startswith('['):  # Make sure its not just another header tag\n",
    "                temp_game['moves'] = moves  # Attach  moves to the current game\n",
    "\n",
    "                # Count mistakes from the moves with the function\n",
    "                (\n",
    "                    temp_game['white_inaccuracies'],\n",
    "                    temp_game['white_mistakes'],\n",
    "                    temp_game['white_blunders'],\n",
    "                    temp_game['black_inaccuracies'],\n",
    "                    temp_game['black_mistakes'],\n",
    "                    temp_game['black_blunders']\n",
    "                ) = count_mistakes(moves)\n",
    "\n",
    "                games.append(temp_game)  \n",
    "                temp_game = None \n",
    "\n",
    "    if temp_game:\n",
    "        games.append(temp_game)  \n",
    "\n",
    "    return games\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf361ff",
   "metadata": {},
   "source": [
    "## Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed0be774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(games, filename='lichess_user_games.csv'):\n",
    "    \"\"\"Save the collected game data to a CSV file.\"\"\"\n",
    "    df = pd.DataFrame(games)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Saved {len(games)} games to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5ccdc0",
   "metadata": {},
   "source": [
    "# Master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f49a86",
   "metadata": {},
   "source": [
    "Output has been cleared for obvious reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71659d57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "team_ids = ['lichess-swiss' ,'coders', 'bengal-tiger', 'im-eric-rosen-fan-club', 'zhigalko_sergei-fan-club', 'arab-world-team']  # Replace with your list of team IDs\n",
    "\n",
    "all_games = []\n",
    "\n",
    "for team_id in team_ids:\n",
    "    print(f\"Fetching members for team: {team_id}\")\n",
    "    members = get_team_members(team_id, max_members = 500)  # Fetch members for the current team\n",
    "    \n",
    "    if members:\n",
    "        for member in members:\n",
    "            username = member['id']  # 'id' = username\n",
    "            print(f\"Fetching games for user: {username} from team: {team_id}\")\n",
    "            pgn_data = get_user_analyzed_games(username, max_games=10)  # Limit to 10 games per user \n",
    "            \n",
    "            if pgn_data:\n",
    "                games = process_pgn_data_with_mistakes(pgn_data) \n",
    "                all_games.extend(games)\n",
    "    else:\n",
    "        print(f\"No members found or error retrieving members for team: {team_id}\")\n",
    "    \n",
    "    print(f\"Finished team: {team_id}. Total games collected: {len(all_games)} rows\")\n",
    "\n",
    "save_to_csv(all_games, 'games1.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
